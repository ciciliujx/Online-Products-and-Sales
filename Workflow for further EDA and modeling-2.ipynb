{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "10d7c263-194b-4d16-bd62-1a062d5eba6f",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis: PCA\n",
    "\n",
    "<span style=\"color:red\">The language is too technical to read.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eca841f4-523f-47ef-8e82-9702ac828f8d",
   "metadata": {
    "tags": []
   },
   "source": [
    "Intuitively speaking, the price, volume of sales and customers' ratings of a good are always inter-correlated. For instance, if a good is sold at a relatively low price and the customer reflection on their user experience is above the average, then it is reasonable to infer that the quality and competitiveness of this good may be guaranteed and the sale volume is highly likely to be high. \n",
    "\n",
    "Therefore, in order to investigate how the variation between goods are contributed by the combination of price, sales volume and customers' rating, on our second last stage of Exploratory Data Analysis, we decide to conduct Principal Component Analysis(PCA) on our data. We would assume that our data approximately lies on a hyperplane and Euclidean distance would be used. Note that we would exclude the categorical variable \"category\" from our data.\n",
    "\n",
    "<span style=\"color:red\">!!! Need to elaborate more on why we chose PCA (its features and how it can resolve our problem)</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3385d93e-683d-4cd9-84fe-819b26c93e0c",
   "metadata": {},
   "source": [
    "Usually PCA is conducted through applying Singular Value Decomposition(SVD) on the centered data or applying Eigenvalue Decomposition on the covariance matrix of the centered data. Meanwhile, the unit of variable may influence the performance of PCA; variable in a larger scale usually contribute more on the overall variation. To address this concern, we will standardize the data by scaling and centering it before implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17ec7668-fb8d-4678-a8aa-be2e84835772",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Standardize the data and preview the preprocessed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db162b19-15a2-4974-8622-930736f0c717",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Apply the PCA on preprocessed data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8a8e22f-302e-4605-99fd-041e9de2a6dc",
   "metadata": {},
   "source": [
    "Determining the number of principal components K involved would be the next stage of PCA, and it is usually measured by the proportion of variation explained by each PC. Usually cross-validation is proposed when the data is assumed to be random and the prediction ability of PCA is valued. For exploratory data analysis, finding the elbow point of a scree-plot is usually the most common way to choose K. Also, since the corresponding eigenvalues of those PCs are monotonically decreasing, picking the PCs whose eigenvalues is larger than average can be an alternative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "240a417d-be02-48e1-907a-36eb9a0a0bd4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# The scree-plot of PCA (our result is most likely to be PC1 (and PC2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c8a7eaa-5d9f-4d26-82da-1df6e16ac601",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The plot of eigenvalues (with a threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f648ef5-e59f-4d44-8d9c-7e8cc945646a",
   "metadata": {},
   "source": [
    "Also, back to our motivation to conduct PCA, the most we wonder about is how price, rating and rating counts contribute to those important principal components. For this, we may check the coefficients of each variable in the loading of each PC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "89058939-8e7d-4886-bf2c-41a3e858f2e7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# The loading plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "36847e4d-499a-4005-bd19-aa0bda59c451",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Another way to show the relationship between raw variables and PC1,2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b71fa59a-5928-4a69-8f18-a6c14526fb2d",
   "metadata": {},
   "source": [
    "From the scree-plots and loading plots, we may conclude that ......"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce3b7676-c85a-4145-a7f9-00687be21098",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis: Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e64786df-109e-4a7d-869e-65538e61321f",
   "metadata": {},
   "source": [
    "Besides how the variation of data is contributed, we are also interested in if the variation in data lead to specific structure of data in the context of price and customers' feedback, where another unsupervised learning method may be explored: clustering. Usually, K-means clustering, Guassian model-based clustering and hierarchical clutering may be proposed. Considering that we lack the evidence for the assumption that data is generated under a mixture of guassian distribution, and the visualization of hierarchical clustering may be blurred, K-means clustering seems to be an appropriate choice here.\n",
    "\n",
    "<span style=\"color:red\">!!! Make why using clustering more explicit</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e55faf34-da72-4484-b58b-2cae79326f63",
   "metadata": {},
   "source": [
    "Note that since our data has a relatively low dimension, the issue of \"curse of dimensionality\" would be less serious, and thus we would rather applying clustering to raw variables instead of principle components. Also, though centering is unnecessary for clustering, we still need to scale the data since Euclidean distance is used.\n",
    "\n",
    "<span style=\"color:red\">!!! Explain \"curse of dimensionality\" </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6f7980d2-d0ef-47a1-bb24-d253613e8e3b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Scale the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0090bfce-92c4-4623-9227-8ee3ee8840dc",
   "metadata": {},
   "source": [
    "The result of clustering should be intuitively interpretable, but the randomness in selecting the initial centriods to start may lead to results that are counter-intuitive. Thus, for certain k clusters we may need to run the code multiple times. Meanwhile, we also need to determine the best number of clusters fitted. The common practices are applying CH index or comparing the within-cluster sum of squared distance. Here we would use the latter for tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "91083040-cf03-4617-91dd-0be634357c92",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# For k from 1 to 5, run k-means clustering on data for 15 times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "68916017-8c6a-4594-84a8-d8011649d221",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a data frame to store the k and corresponding within-cluster sum of squared distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f42a3a6c-73c8-4a44-9c30-b4499411b34b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the WCSSD against k and seek the elbow point"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3afad97-c946-4ffc-be3c-56673bb4eb3a",
   "metadata": {},
   "source": [
    "As what we emphasized before, the intuitive interpretation of clustering output matters. However, it would be visually difficult to examine the reasonability of the result, since the dimensionality of data is larger than 2. Considering that for customers discounted price may be more important, and it is intuitively correlated to raw price, we may plot those clusters on discounted price against rating and rating against rating count (we may find a function to plot a 3-D clustering plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3acbbf7b-6a33-4c63-95f8-d88a7978c4e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# two 2-D plots or one 3-D plots for the clustering result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dc783ef3-8b4f-429c-aad9-ee073577e4ca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# report the average price, discounted price, rating and rating-count of each cluster under optimal k"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8de50edc-a652-4d8b-809f-30bb1b4ca3ec",
   "metadata": {},
   "source": [
    "We may interpret such an answer that ......"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f9969226-fe3e-4f93-92b4-fbf3eee2398d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternatively, we may compare the proportion of each category in overall data and in each cluster"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
